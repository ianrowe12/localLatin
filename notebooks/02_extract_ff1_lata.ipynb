{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extract LaTa FF1 post-activation embeddings\n",
        "\n",
        "This extracts the encoder FF1 post-activation representations (input to `wo`) for layers 1..12.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "\n",
        "\n",
        "def in_colab() -> bool:\n",
        "    return \"COLAB_GPU\" in os.environ or \"COLAB_RELEASE_TAG\" in os.environ\n",
        "\n",
        "\n",
        "if in_colab():\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "    REPO_URL = os.environ.get(\"REPO_URL\", \"https://github.com/ianrowe12/localLatin.git\")\n",
        "    REPO_ROOT = Path(os.environ.get(\"REPO_ROOT\", \"/content/localLatin\"))\n",
        "    if not REPO_ROOT.exists():\n",
        "        !git clone {REPO_URL}\n",
        "\n",
        "    CANON_ROOT = Path(os.environ.get(\"CANON_ROOT\", \"/content/drive/MyDrive/localLatin_data/canon\"))\n",
        "    RUNS_ROOT = Path(os.environ.get(\"RUNS_ROOT\", \"/content/drive/MyDrive/localLatin_runs/ff1_lata_postact\"))\n",
        "else:\n",
        "    REPO_ROOT = Path(os.environ.get(\"REPO_ROOT\", \"/Users/ianrowe/git/localLatin\"))\n",
        "    CANON_ROOT = Path(os.environ.get(\"CANON_ROOT\", str(REPO_ROOT / \"canon\")))\n",
        "    RUNS_ROOT = Path(os.environ.get(\"RUNS_ROOT\", str(REPO_ROOT / \"runs\" / \"ff1_lata_postact\")))\n",
        "\n",
        "sys.path.append(str(REPO_ROOT / \"src\"))\n",
        "\n",
        "print(f\"REPO_ROOT: {REPO_ROOT}\")\n",
        "print(f\"CANON_ROOT: {CANON_ROOT}\")\n",
        "print(f\"RUNS_ROOT: {RUNS_ROOT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "from canon_retrieval import l2_normalize, load_texts, save_json\n",
        "\n",
        "META_CSV = str(RUNS_ROOT / \"meta.csv\")\n",
        "MODEL_NAME = \"bowphs/LaTa\"\n",
        "MAX_LENGTH = 512\n",
        "BATCH_SIZE = 12\n",
        "\n",
        "run_id = datetime.now().strftime(\"run_%Y%m%d_%H%M%S\")\n",
        "RUN_DIR = str(RUNS_ROOT / run_id)\n",
        "Path(RUN_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "meta = pd.read_csv(META_CSV)\n",
        "paths = meta[\"path\"].tolist()\n",
        "\n",
        "print(f\"Run dir: {RUN_DIR}\")\n",
        "print(f\"Files: {len(paths)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "encoder = model.get_encoder() if hasattr(model, \"get_encoder\") else model.encoder\n",
        "encoder.to(device)\n",
        "encoder.eval()\n",
        "\n",
        "config = {\n",
        "    \"model_name\": MODEL_NAME,\n",
        "    \"max_length\": MAX_LENGTH,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"hook_point\": \"ff1_post_activation_input_to_wo\",\n",
        "    \"layers\": list(range(1, len(encoder.block) + 1)),\n",
        "    \"timestamp\": run_id,\n",
        "}\n",
        "\n",
        "save_json(f\"{RUN_DIR}/config.json\", config)\n",
        "meta.to_csv(f\"{RUN_DIR}/meta.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_ffn_wo(layer_module: torch.nn.Module) -> torch.nn.Module:\n",
        "    if hasattr(layer_module, \"DenseReluDense\"):\n",
        "        return layer_module.DenseReluDense.wo\n",
        "    if hasattr(layer_module, \"DenseGatedGeluDense\"):\n",
        "        return layer_module.DenseGatedGeluDense.wo\n",
        "    if hasattr(layer_module, \"wo\"):\n",
        "        return layer_module.wo\n",
        "    raise AttributeError(\"Could not find FFN wo module\")\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def extract_layer_embeddings(layer_idx: int) -> np.ndarray:\n",
        "    ffn_layer = encoder.block[layer_idx].layer[1]\n",
        "    wo = get_ffn_wo(ffn_layer)\n",
        "    captured: list[torch.Tensor] = []\n",
        "\n",
        "    def hook(module, inputs):\n",
        "        captured.append(inputs[0])\n",
        "\n",
        "    handle = wo.register_forward_pre_hook(hook)\n",
        "\n",
        "    embeddings = []\n",
        "    for start in range(0, len(paths), BATCH_SIZE):\n",
        "        batch_paths = paths[start : start + BATCH_SIZE]\n",
        "        batch_texts = load_texts(batch_paths)\n",
        "        enc = tokenizer(\n",
        "            batch_texts,\n",
        "            truncation=True,\n",
        "            max_length=MAX_LENGTH,\n",
        "            padding=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        input_ids = enc[\"input_ids\"].to(device)\n",
        "        attention_mask = enc[\"attention_mask\"].to(device)\n",
        "        captured.clear()\n",
        "        _ = encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        if len(captured) != 1:\n",
        "            raise RuntimeError(f\"Expected 1 capture, got {len(captured)}\")\n",
        "        ff_act = captured[0]\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (ff_act * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1.0)\n",
        "        embeddings.append(pooled.detach().cpu().numpy().astype(np.float32))\n",
        "\n",
        "    handle.remove()\n",
        "    return np.concatenate(embeddings, axis=0)\n",
        "\n",
        "\n",
        "for layer_idx in range(len(encoder.block)):\n",
        "    layer_num = layer_idx + 1\n",
        "    print(f\"Extracting layer {layer_num}...\")\n",
        "    emb = extract_layer_embeddings(layer_idx)\n",
        "    emb_norm = l2_normalize(emb)\n",
        "    np.save(f\"{RUN_DIR}/ff1_layer{layer_num}_embeddings.npy\", emb)\n",
        "    np.save(f\"{RUN_DIR}/ff1_layer{layer_num}_embeddings_norm.npy\", emb_norm)\n",
        "\n",
        "print(\"Done.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "key_path = os.environ.get(\"DRIVE_SA_KEY_PATH\", \"/content/sa_drive_key.json\")\n",
        "if Path(key_path).exists():\n",
        "    env = os.environ.copy()\n",
        "    env[\"DRIVE_SA_KEY_PATH\"] = key_path\n",
        "    subprocess.run(\n",
        "        [\"python\", \"-m\", \"src.drive_sync\", \"--local_run_dir\", RUN_DIR],\n",
        "        cwd=str(REPO_ROOT),\n",
        "        env=env,\n",
        "        check=True,\n",
        "    )\n",
        "    print(\"Synced run to Drive.\")\n",
        "else:\n",
        "    print(f\"Drive key not found at {key_path}; skipping sync.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
