{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluate FF1 retrieval and PR/F1\n",
        "\n",
        "Compute Accuracy@K and threshold PR/F1 for each FF1 layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "\n",
        "\n",
        "def in_colab() -> bool:\n",
        "    return \"COLAB_GPU\" in os.environ or \"COLAB_RELEASE_TAG\" in os.environ\n",
        "\n",
        "\n",
        "if in_colab():\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\")\n",
        "    REPO_ROOT = Path(os.environ.get(\"REPO_ROOT\", \"/content/localLatin\"))\n",
        "    CANON_ROOT = Path(os.environ.get(\"CANON_ROOT\", \"/content/drive/MyDrive/localLatin_data/canon\"))\n",
        "    RUNS_ROOT = Path(os.environ.get(\"RUNS_ROOT\", \"/content/drive/MyDrive/localLatin_runs/ff1_lata_postact\"))\n",
        "else:\n",
        "    def find_repo_root(start: Path) -> Path:\n",
        "        for candidate in [start, *start.parents]:\n",
        "            if (candidate / \"canon\").exists() and (candidate / \"src\").exists():\n",
        "                return candidate\n",
        "        raise FileNotFoundError(\"Could not locate repo root containing canon/ and src/\")\n",
        "\n",
        "    REPO_ROOT = Path(os.environ.get(\"REPO_ROOT\", \"\")) if os.environ.get(\"REPO_ROOT\") else find_repo_root(Path.cwd())\n",
        "    CANON_ROOT = Path(os.environ.get(\"CANON_ROOT\", str(REPO_ROOT / \"canon\")))\n",
        "    RUNS_ROOT = Path(os.environ.get(\"RUNS_ROOT\", str(REPO_ROOT / \"runs\" / \"ff1_lata_postact\")))\n",
        "\n",
        "sys.path.append(str(REPO_ROOT / \"src\"))\n",
        "\n",
        "print(f\"REPO_ROOT: {REPO_ROOT}\")\n",
        "print(f\"CANON_ROOT: {CANON_ROOT}\")\n",
        "print(f\"RUNS_ROOT: {RUNS_ROOT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from canon_retrieval import (\n",
        "    accuracy_at_k,\n",
        "    l2_normalize,\n",
        "    sanity_checks,\n",
        "    similarity_matrix,\n",
        "    sweep_thresholds,\n",
        "    upper_triangle,\n",
        "    upper_triangle_labels,\n",
        ")\n",
        "\n",
        "RUN_DIR = None  # set to a specific run folder, e.g. f\"{RUNS_ROOT}/run_YYYYMMDD_HHMMSS\"\n",
        "\n",
        "if RUN_DIR is None:\n",
        "    candidates = sorted(Path(RUNS_ROOT).glob(\"run_*/\"))\n",
        "    if not candidates:\n",
        "        raise FileNotFoundError(\"No run_* folder found. Run extraction first.\")\n",
        "    RUN_DIR = str(candidates[-1])\n",
        "\n",
        "meta = pd.read_csv(f\"{RUN_DIR}/meta.csv\")\n",
        "folder_ids = meta[\"folder_id\"].tolist()\n",
        "is_winnable = meta[\"is_winnable\"].tolist()\n",
        "\n",
        "print(f\"Using run: {RUN_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "layer_rows = []\n",
        "threshold_rows = []\n",
        "\n",
        "for layer_num in range(1, 13):\n",
        "    emb_path = f\"{RUN_DIR}/ff1_layer{layer_num}_embeddings_norm.npy\"\n",
        "    emb = np.load(emb_path)\n",
        "\n",
        "    sim = similarity_matrix(emb)\n",
        "    checks = sanity_checks(sim)\n",
        "\n",
        "    acc1 = accuracy_at_k(sim, folder_ids, is_winnable, k=1)\n",
        "    acc3 = accuracy_at_k(sim, folder_ids, is_winnable, k=3)\n",
        "    acc5 = accuracy_at_k(sim, folder_ids, is_winnable, k=5)\n",
        "\n",
        "    sim_upper = upper_triangle(sim)\n",
        "    labels = upper_triangle_labels(folder_ids)\n",
        "    thresholds = np.linspace(sim_upper.min(), sim_upper.max(), 400)\n",
        "    curve = sweep_thresholds(sim_upper, labels, thresholds)\n",
        "    curve[\"layer\"] = layer_num\n",
        "    curve.to_csv(f\"{RUN_DIR}/threshold_curve_layer{layer_num}.csv\", index=False)\n",
        "\n",
        "    best_idx = curve[\"f1\"].idxmax()\n",
        "    best_row = curve.loc[best_idx]\n",
        "\n",
        "    layer_rows.append(\n",
        "        {\n",
        "            \"layer\": layer_num,\n",
        "            \"acc@1\": acc1,\n",
        "            \"acc@3\": acc3,\n",
        "            \"acc@5\": acc5,\n",
        "            \"best_threshold\": float(best_row[\"threshold\"]),\n",
        "            \"best_precision\": float(best_row[\"precision\"]),\n",
        "            \"best_recall\": float(best_row[\"recall\"]),\n",
        "            \"best_f1\": float(best_row[\"f1\"]),\n",
        "            \"diag_mean\": checks[\"diag_mean\"],\n",
        "            \"off_diag_mean\": checks[\"off_diag_mean\"],\n",
        "        }\n",
        "    )\n",
        "\n",
        "summary = pd.DataFrame(layer_rows)\n",
        "summary.to_csv(f\"{RUN_DIR}/ff1_layer_summary.csv\", index=False)\n",
        "summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(summary[\"layer\"], summary[\"acc@1\"], label=\"Acc@1\")\n",
        "plt.plot(summary[\"layer\"], summary[\"acc@3\"], label=\"Acc@3\")\n",
        "plt.plot(summary[\"layer\"], summary[\"acc@5\"], label=\"Acc@5\")\n",
        "plt.xlabel(\"Layer\")\n",
        "plt.ylabel(\"Accuracy@K\")\n",
        "plt.title(\"FF1 post-activation retrieval accuracy\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
